{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-08T01:44:52.267741Z",
     "start_time": "2025-10-08T01:44:52.264387Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "from tqdm.autonotebook import tqdm"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T02:34:45.056986Z",
     "start_time": "2025-10-08T02:34:31.729259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AGGREGATE_RESULT_FILE_PATH = \"outputs/manitoba_rcm_ard/collection.parquet\"\n",
    "AGGREGATE_SEARCH_DIR_PATH = \"./outputs/manitoba_rcm_ard/IGEO7\"\n",
    "\n",
    "# distinct dataframes with similar variables to aggregate together\n",
    "AGGREGATE_ZONE_VARIABLES = [\"rr\", \"rl\"]\n",
    "# columns used as ID to merge corresponding zones\n",
    "# (note: if datetime-aware, should include a temporal component as well)\n",
    "AGGREGATE_ZONE_ID_COLUMNS = [\"dggrid_ISEA7H\", \"day\"]\n",
    "# any column renaming (replace) to perform prior to aggregation and merging\n",
    "# (note: below extended columns are affected by this change applied before)\n",
    "AGGREGATE_RENAME_COLUMNS = {\n",
    "    \"cell_\": \"\",\n",
    "}\n",
    "# columns to extend with the relevant above variable prefix (others merged as is / duplicates)\n",
    "AGGREGATE_EXTEND_COLUMNS = [\n",
    "    \"minimum\",\n",
    "    \"maximum\",\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "    \"stddev\",\n",
    "]\n",
    "\n",
    "agg_zone_data = []\n",
    "agg_walk_progress = tqdm(\n",
    "    os.walk(AGGREGATE_SEARCH_DIR_PATH),\n",
    "    desc=\"Aggregating zone data\",\n",
    ")\n",
    "for root_dir, sub_dirs, _ in agg_walk_progress:\n",
    "    if sub_dirs != AGGREGATE_ZONE_VARIABLES:\n",
    "        continue\n",
    "\n",
    "    merge_zone_data = None\n",
    "    for sub_dir in sub_dirs:\n",
    "        cur = root_dir.replace(AGGREGATE_SEARCH_DIR_PATH, \"\").strip(\"/\")\n",
    "        agg_walk_progress.set_postfix(current=cur)\n",
    "        file_names = os.listdir(str(os.path.join(root_dir, sub_dir)))\n",
    "        for file_name in file_names:\n",
    "            if not file_name.endswith(\".parquet\"):\n",
    "                continue\n",
    "            try:\n",
    "                file_path = os.path.join(root_dir, sub_dir, file_name)\n",
    "                zone_data_var = gpd.read_parquet(file_path)\n",
    "                zone_data_col_rename = {\n",
    "                    col: col.replace(old, new)\n",
    "                    for old, new in AGGREGATE_RENAME_COLUMNS.items()\n",
    "                    for col in zone_data_var.columns\n",
    "                }\n",
    "                zone_data_var = zone_data_var.rename(columns=zone_data_col_rename)\n",
    "                zone_data_col_merge = {\n",
    "                    col: f\"{sub_dir}_{col}\"\n",
    "                    for col in AGGREGATE_EXTEND_COLUMNS\n",
    "                }\n",
    "                zone_data_var = zone_data_var.rename(columns=zone_data_col_merge)\n",
    "                if merge_zone_data is None:\n",
    "                    merge_zone_data = zone_data_var\n",
    "                else:\n",
    "                    merge_zone_cols = AGGREGATE_ZONE_ID_COLUMNS + list(zone_data_col_merge.values())\n",
    "                    merge_zone_data = merge_zone_data.merge(\n",
    "                        zone_data_var[merge_zone_cols],\n",
    "                        on=AGGREGATE_ZONE_ID_COLUMNS,\n",
    "                        how=\"outer\",\n",
    "                        suffixes=(\"\", \"\"),  # raise if something went wrong, don't do silent fixes\n",
    "                    )\n",
    "                break  # in case many were found, ignore others (cannot merge anyway / no priority)\n",
    "            except Exception as exc:\n",
    "                err_msg = f\"Error while processing [{file_path}]: {exc}\"\n",
    "                raise Exception(err_msg) from exc\n",
    "\n",
    "    agg_zone_data.append(merge_zone_data)\n",
    "    sub_dirs[:] = []  # don't recurse further\n",
    "\n",
    "agg_zone_data = gpd.pd.concat(agg_zone_data, ignore_index=True)\n",
    "agg_zone_data = agg_zone_data.sort_values(\n",
    "    by=[\"resolution\", \"datetime\"],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "agg_zone_data.to_parquet(AGGREGATE_RESULT_FILE_PATH)"
   ],
   "id": "1e00e107a03f737c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggregating zone data: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30792ff79c9e4acda20065b76c39bb37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "Error while processing [./outputs/manitoba_rcm_ard/IGEO7/L7/2025-09-01/rl/RCM1_OK3555385_PK3778047_1_SC30MCPA_20250901_000600_RL.parquet]: \"['day'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 59\u001B[39m\n\u001B[32m     57\u001B[39m     merge_zone_cols = AGGREGATE_ZONE_ID_COLUMNS + \u001B[38;5;28mlist\u001B[39m(zone_data_col_merge.values())\n\u001B[32m     58\u001B[39m     merge_zone_data = merge_zone_data.merge(\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m         \u001B[43mzone_data_var\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmerge_zone_cols\u001B[49m\u001B[43m]\u001B[49m,\n\u001B[32m     60\u001B[39m         on=AGGREGATE_ZONE_ID_COLUMNS,\n\u001B[32m     61\u001B[39m         how=\u001B[33m\"\u001B[39m\u001B[33mouter\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     62\u001B[39m         suffixes=(\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m),  \u001B[38;5;66;03m# raise if something went wrong, don't do silent fixes\u001B[39;00m\n\u001B[32m     63\u001B[39m     )\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# in case many were found, ignore others (cannot merge anyway / no priority)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/miniconda/envs/pydggsapi/lib/python3.12/site-packages/geopandas/geodataframe.py:1750\u001B[39m, in \u001B[36mGeoDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[33;03mIf the result is a column containing only 'geometry', return a\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[33;03mGeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001B[39;00m\n\u001B[32m   1748\u001B[39m \u001B[33;03mreturn a GeoDataFrame.\u001B[39;00m\n\u001B[32m   1749\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1751\u001B[39m \u001B[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001B[39;00m\n\u001B[32m   1752\u001B[39m \u001B[38;5;66;03m# result is not geometry dtype for multi-indexes\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/miniconda/envs/pydggsapi/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4112\u001B[39m         key = \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m     indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcolumns\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[32m1\u001B[39m]\n\u001B[32m   4115\u001B[39m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/miniconda/envs/pydggsapi/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001B[39m, in \u001B[36mIndex._get_indexer_strict\u001B[39m\u001B[34m(self, key, axis_name)\u001B[39m\n\u001B[32m   6210\u001B[39m     keyarr, indexer, new_indexer = \u001B[38;5;28mself\u001B[39m._reindex_non_unique(keyarr)\n\u001B[32m-> \u001B[39m\u001B[32m6212\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6214\u001B[39m keyarr = \u001B[38;5;28mself\u001B[39m.take(indexer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/miniconda/envs/pydggsapi/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001B[39m, in \u001B[36mIndex._raise_if_missing\u001B[39m\u001B[34m(self, key, indexer, axis_name)\u001B[39m\n\u001B[32m   6263\u001B[39m not_found = \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask.nonzero()[\u001B[32m0\u001B[39m]].unique())\n\u001B[32m-> \u001B[39m\u001B[32m6264\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m not in index\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyError\u001B[39m: \"['day'] not in index\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mException\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 67\u001B[39m\n\u001B[32m     65\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     66\u001B[39m             err_msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mError while processing [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(err_msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n\u001B[32m     69\u001B[39m agg_zone_data.append(merge_zone_data)\n\u001B[32m     70\u001B[39m sub_dirs[:] = []  \u001B[38;5;66;03m# don't recurse further\u001B[39;00m\n",
      "\u001B[31mException\u001B[39m: Error while processing [./outputs/manitoba_rcm_ard/IGEO7/L7/2025-09-01/rl/RCM1_OK3555385_PK3778047_1_SC30MCPA_20250901_000600_RL.parquet]: \"['day'] not in index\""
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
